{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "LSTM_TA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN1_SEXfN5iU"
      },
      "source": [
        "<div align=\"left\">\n",
        "  <h1>LSTM</h1> <a name=\"0-bullet\"></a>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wYzWw5vOOmk"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdhnjASadtie"
      },
      "source": [
        "# Text Generation\n",
        "Adapted from code at https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr1VAQcvdtih"
      },
      "source": [
        "'''Example script to generate text from sample text.\n",
        "\n",
        "At least 20 epochs are required before the generated text\n",
        "starts sounding coherent.\n",
        "\n",
        "It is recommended to run this script on GPU, as recurrent\n",
        "networks are quite computationally intensive.\n",
        "\n",
        "If you try this script on new data, make sure your corpus\n",
        "has at least ~100k characters. ~1M is better.\n",
        "'''\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import LambdaCallback, EarlyStopping\n",
        "from keras.layers import Dense, Activation, Embedding, Dropout, Bidirectional\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.data_utils import get_file\n",
        "import tensorflow as tf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import sys\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1_DFfysdtiq"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQSvI3vAHAj_",
        "outputId": "7128ac42-943c-4c77-a0a6-5a776195c9a5"
      },
      "source": [
        "# mounting the Drive folder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA0fsB0kkO3P"
      },
      "source": [
        "# loading the lyric dataset by taking english songs only\n",
        "lyrics = pd.read_csv('/content/drive/MyDrive/Text_Analytics/Data/lyrics-data.csv')\n",
        "lyrics = lyrics[lyrics['Idiom']=='ENGLISH']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwAtlcoelmzH"
      },
      "source": [
        "#Only keep popular artists, with genre Rock/Pop and popularity high enough\n",
        "artists = pd.read_csv('/content/drive/MyDrive/Text_Analytics/Data/artists-data.csv')\n",
        "\n",
        "artists = artists[(artists['Genre'].isin(['Rock'])) & (artists['Popularity']>5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSqrEXq-nbdf"
      },
      "source": [
        "# merge of the datasets\n",
        "\n",
        "df = lyrics.merge(artists[['Artist', 'Genre', 'Link']], left_on='ALink', right_on='Link', how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcPK_kr2oEs4"
      },
      "source": [
        "# dropping all the columns that we will not use for this task\n",
        "\n",
        "df = df.drop(columns=['ALink','SLink','Idiom','Link'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OiRCSfLDHV-"
      },
      "source": [
        "# taking only the lyrics with less than 350 chars, this will simple the fine-tuning phase\n",
        "\n",
        "df = df[df['Lyric'].apply(lambda x: len(x.split(' ')) < 350)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "rVboqSeuAqmb",
        "outputId": "9c05a01c-def6-4843-af37-fa72e79d27a2"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SName</th>\n",
              "      <th>Lyric</th>\n",
              "      <th>Artist</th>\n",
              "      <th>Genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What's Up</td>\n",
              "      <td>Twenty-five years and my life is still. Trying...</td>\n",
              "      <td>4 Non Blondes</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Spaceman</td>\n",
              "      <td>Starry night bring me down. Till I realize the...</td>\n",
              "      <td>4 Non Blondes</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pleasantly Blue</td>\n",
              "      <td>Every time you wake in the mornin'. And you st...</td>\n",
              "      <td>4 Non Blondes</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Train</td>\n",
              "      <td>What ya gonna do child. When your thoughts are...</td>\n",
              "      <td>4 Non Blondes</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Calling All The People</td>\n",
              "      <td>How can you tell, when your wellness is not we...</td>\n",
              "      <td>4 Non Blondes</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    SName  ... Genre\n",
              "0               What's Up  ...  Rock\n",
              "1                Spaceman  ...  Rock\n",
              "2         Pleasantly Blue  ...  Rock\n",
              "3                   Train  ...  Rock\n",
              "4  Calling All The People  ...  Rock\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XEP40sk-fig"
      },
      "source": [
        "# in order to train the model for the text generation we need to create a unique file by separating each song with a start and end label\n",
        "SOT = \"<SOT>\"     # start of text\n",
        "EOT = \"<EOT>\"     # end of text\n",
        "df_lyrics = df['Lyric'].apply(lambda lyrics: SOT + lyrics + EOT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "EB286FOVIGwD",
        "outputId": "aa1a98fe-70dc-4b63-98fa-de523e58571b"
      },
      "source": [
        "df_lyrics[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<SOT>Twenty-five years and my life is still. Trying to get up that great big hill of hope. For a destination.. I realized quickly when I knew I should. That the world was made up of this. brotherhood of man. For whatever that means. And so I cry sometimes. When I'm lying in bed Just to get it all out. What's in my head. And I, I am feeling a little peculiar.. And so I wake up in the morning. And I step outside. And I take a deep breath and I get real high. And I scream from the top of my lungs. What's going on?. And I say: Hey! yeah yeaaah, Hey yeah yea. I said hey, what's going on?. And I say: Hey! yeah yeaaah, Hey yeah yea. I said hey, what's going on?. ooh, ooh ooh. and I try, oh my god do I try. I try all the time, in this institution. And I pray, oh my god do I pray. I pray every single day. For a revolution.. And so I cry sometimes. When I'm lying bed. Just to get it all out. What's in my head. And I, I am feeling a little peculiar. And so I wake up in the morning. And I step outside. And I take a deep breath and I get real high. And I scream from the top of my lungs. What's going on?. And I say, hey hey hey hey. I said hey, what's going on?. Twenty-five years and my life is still. Trying to get up that great big hill of hope. for a destination.<EOT>\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXmDQ6p2-fgC"
      },
      "source": [
        "# then each song will be separeted by a new line, this will let the model understand better the structure of the text\n",
        "text = '\\n\\n\\n'.join(df_lyrics.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA_Ew207dti4"
      },
      "source": [
        "## Text vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RypnaSlRdti5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c152abaa-a8a8-4954-bb7b-738c6d0df464"
      },
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gQj645Qdti_"
      },
      "source": [
        "# drastically cut the number of sequences only to allow a fast execution during lesson\n",
        "sentences = sentences[:50000]\n",
        "next_chars = next_chars[:50000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGSqkTuDdtjG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "56b33a39-1e4f-408f-c9b4-e618987eaeff"
      },
      "source": [
        "sentences[3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ty-five years and my life is still. Tryi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQVDW1aBdtjM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e6417c3c-3b71-40bc-909a-c8fad4c38281"
      },
      "source": [
        "next_chars[3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ede1U2X0dtjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5055a5b4-fd91-41e0-ed92-99e89f97f177"
      },
      "source": [
        "print('training sequences:', len(sentences))\n",
        "print('vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.int)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.int)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "print('done.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training sequences: 50000\n",
            "vectorization...\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1j2ujfvdtjY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48255452-4a05-4903-bf29-e4f146ee48f8"
      },
      "source": [
        "x[3],y[3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]),\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WntcFCQdtjc"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxOlYxZ1vmtc"
      },
      "source": [
        "# model = Sequential()\n",
        "# model.add(LSTM(256, input_shape=(maxlen, len(chars))))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Dense(len(chars), activation='softmax'))\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwZHON1HseZc",
        "outputId": "ef59c807-d6a0-4cf2-c0c3-4bb1af7b650b"
      },
      "source": [
        "# this is the model that will be used for the training, here there is also a Bideractional layer that is more useful for large text sequences\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(256), input_shape=(maxlen, len(chars))))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional (Bidirectional (None, 512)               870400    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 168)               86184     \n",
            "=================================================================\n",
            "Total params: 956,584\n",
            "Trainable params: 956,584\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWpBxDYYdtji"
      },
      "source": [
        "## Functions to generate text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEqU3miLdtjj"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- temperature:', temperature)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        print('Seed:')\n",
        "        print(sentence)\n",
        "        print('------')\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, temperature)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            sentence = sentence[1:] + next_char\n",
        "            generated += next_char\n",
        "\n",
        "        print('Generated text:')\n",
        "        print(generated)\n",
        "        print('------')\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7G3xXzzdtjo"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ijSIWFqdtjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ff1465-fef8-4d72-92ee-16e933ab2e2c"
      },
      "source": [
        "# train the model, output generated text after each epoch\n",
        "model.fit(x, y,\n",
        "          batch_size=64,\n",
        "          epochs=10,\n",
        "          validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "704/704 [==============================] - 317s 418ms/step - loss: 3.1758 - accuracy: 0.2093 - val_loss: 2.3360 - val_accuracy: 0.3484\n",
            "Epoch 2/10\n",
            "704/704 [==============================] - 297s 421ms/step - loss: 2.2420 - accuracy: 0.3689 - val_loss: 2.1107 - val_accuracy: 0.3892\n",
            "Epoch 3/10\n",
            "704/704 [==============================] - 304s 431ms/step - loss: 2.0343 - accuracy: 0.4144 - val_loss: 1.9798 - val_accuracy: 0.4380\n",
            "Epoch 4/10\n",
            "704/704 [==============================] - 299s 425ms/step - loss: 1.8533 - accuracy: 0.4643 - val_loss: 1.8857 - val_accuracy: 0.4498\n",
            "Epoch 5/10\n",
            "704/704 [==============================] - 297s 422ms/step - loss: 1.7353 - accuracy: 0.4961 - val_loss: 1.8439 - val_accuracy: 0.4654\n",
            "Epoch 6/10\n",
            "704/704 [==============================] - 288s 409ms/step - loss: 1.6034 - accuracy: 0.5332 - val_loss: 1.8054 - val_accuracy: 0.4798\n",
            "Epoch 7/10\n",
            "704/704 [==============================] - 287s 408ms/step - loss: 1.5261 - accuracy: 0.5537 - val_loss: 1.7753 - val_accuracy: 0.4802\n",
            "Epoch 8/10\n",
            "704/704 [==============================] - 285s 404ms/step - loss: 1.4132 - accuracy: 0.5874 - val_loss: 1.7911 - val_accuracy: 0.4844\n",
            "Epoch 9/10\n",
            "704/704 [==============================] - 284s 403ms/step - loss: 1.3139 - accuracy: 0.6127 - val_loss: 1.8048 - val_accuracy: 0.4888\n",
            "Epoch 10/10\n",
            "704/704 [==============================] - 282s 401ms/step - loss: 1.2062 - accuracy: 0.6479 - val_loss: 1.8127 - val_accuracy: 0.4906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5af944f350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36NZEkumSR8t"
      },
      "source": [
        "## Comparing ends of the lyrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtXmHEsBdtjv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43530e36-2913-4479-8612-0a89e1487cfd"
      },
      "source": [
        "# testing the tet generation by applying different values of temperature\n",
        "start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "for temperature in [0.2, 0.5, 0.8, 1.0, 1.2]:\n",
        "    print('----- temperature:', temperature)\n",
        "\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    print('Seed:')\n",
        "    print(sentence)\n",
        "    print('------')\n",
        "\n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds, temperature)\n",
        "        next_char = indices_char[next_index]\n",
        "\n",
        "        sentence = sentence[1:] + next_char\n",
        "        generated += next_char\n",
        "    generated = generated.split('.')\n",
        "\n",
        "    print('Generated text:')\n",
        "    print('\\n'.join(generated))\n",
        "    print('------')\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- temperature: 0.2\n",
            "Seed:\n",
            "ut if there's a pill to help me forget. \n",
            "------\n",
            "Generated text:\n",
            "She to down to roll shack\n",
            " You know I know that's got the skind\n",
            " And I way I sake you roll\n",
            " I wan way I gonna baby\n",
            " And I heads of the good to be\n",
            " I got you do I do I do lood down down war hog on my baby\n",
            " And I got you wanna good time\n",
            " Baby blease boogie boogie\n",
            " And I take you got to reall\n",
            " Give it up\n",
            " I to she's gonna get it up\n",
            " Give it up\n",
            " All screwed up\n",
            " It's a broin shake, brain shake, brain s\n",
            "------\n",
            "\n",
            "----- temperature: 0.5\n",
            "Seed:\n",
            "ut if there's a pill to help me forget. \n",
            "------\n",
            "Generated text:\n",
            "Ceall the sard the bous\n",
            " And I take you nothing dorn my spous\n",
            " If you want it up the good on me\n",
            " Hear the por chame to me\n",
            " I got a tound ats me the go down\n",
            " Thook your man't go\n",
            " She said hey hell\n",
            " I got a might to show\n",
            " I wann ay songin' all screttoute\n",
            " I want up it to balky someth me soig fire\n",
            " Thore you want stack for me\n",
            " I'm gonna gove 't up the fight to hell me way to ready\n",
            " Are you ready for \n",
            "------\n",
            "\n",
            "----- temperature: 0.8\n",
            "Seed:\n",
            "ut if there's a pill to help me forget. \n",
            "------\n",
            "Generated text:\n",
            "Carit's givn at some to barcy\n",
            " You know I high a tolight\n",
            " In you wellin' mighta toright\n",
            " AraightarProw be spael\n",
            " I aad my nime\n",
            " There whorey a but I git o forf\n",
            " She the joute for a prinin' (loog in the drimy\n",
            " Are you ready for a good time\n",
            " I But your blood, a good time\n",
            " When shook your good to booghe\n",
            " And they're don't no poright\n",
            " Well itscreey up, get I what I gatht something rock 'n' roll\n",
            " Well \n",
            "------\n",
            "\n",
            "----- temperature: 1.0\n",
            "Seed:\n",
            "ut if there's a pill to help me forget. \n",
            "------\n",
            "Generated text:\n",
            "Car tho you do I doil', poy afrum\n",
            " It's roplin' Big Jack, Com you give it'm holling ont\n",
            " Fordy mo choms no drels on the sind\n",
            " Get o toing dobred ne\n",
            " Get it)\n",
            " Get mans, it,l hild\n",
            " I waln the somin' on mire you woun\n",
            " Then I wetr messing the knigs, stilds offill\n",
            " Teali hoolrst's us it (ievit ine\n",
            " Heve you ontt froniin, wy seatchow mer Doge\n",
            " Cam beadom be best the to and downme, to mancl\n",
            " If reaker sh\n",
            "------\n",
            "\n",
            "----- temperature: 1.2\n",
            "Seed:\n",
            "ut if there's a pill to help me forget. \n",
            "------\n",
            "Generated text:\n",
            "Den't tound, peen my trown<EOT>\n",
            "\n",
            "\n",
            "<S?T>CasQme hayd\n",
            " Yeah reascane anw thomes\n",
            " And theres rocow, de, boonge niem in time\n",
            " 'Cause I'm oh, busn)etrup\n",
            " I'lr deeles, Bady to be breamin't got a m on and rock 'n' roll\n",
            " Ligh oft me haig brdy the lovin\n",
            " Wery to hel 's how-brow?\n",
            "\n",
            "0ThLok ght inlo suecLon\n",
            " Bealbyss all gind wamer mand hille rech thilding\n",
            " Yeah you\n",
            " And thOorelwan\n",
            " And dimaling merande\n",
            " Nous I\n",
            "------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab8wAHD1Sgyl"
      },
      "source": [
        "## Songs similarities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V-yBc2mimiw",
        "outputId": "cbb20e19-1aec-4375-b1c3-e18b63b82b20"
      },
      "source": [
        "# generation of the text with a title taken by an original song from the dataset\n",
        "\n",
        "generated = ''\n",
        "sentence = \"You've Got to Hide Your Love Away\"\n",
        "print('Seed:')\n",
        "print(sentence)\n",
        "print('------')\n",
        "\n",
        "for i in range(400):\n",
        "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(sentence):\n",
        "        x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "    preds = model.predict(x_pred, verbose=0)[0]\n",
        "    next_index = sample(preds, 1.0)\n",
        "    next_char = indices_char[next_index]\n",
        "\n",
        "    sentence = sentence[1:] + next_char\n",
        "    generated += next_char\n",
        "generated = generated.split('.')\n",
        "\n",
        "print('Generated text:')\n",
        "print('\\n'.join(generated))\n",
        "print('------')\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "You've Got to Hide Your Love Away\n",
            "------\n",
            "Generated text:\n",
            "ehHhi--r rr Ul sy\n",
            ",Eh(hie\n",
            "eeee m,ss\n",
            "e\n",
            "s( \n",
            "<ejcyme sr\n",
            "ra!uiK(aatsaaeeeeueehhseYttaoeaeiiyietWuhirtxwdm\n",
            "i\n",
            "\n",
            "tihlh\n",
            "a-\n",
            "S hieea yii r\n",
            "erStnm\n",
            " bii \n",
            "o\n",
            "< Ri-i[riyouaiiii-oaoaooowu[oheheiernitioaiieoauaooowLwh sis)uehhhu iieoa \n",
            "iouiio\"\n",
            "o c\n",
            "  rl \n",
            "l,keTI  aeshraimihotuealiouioaottse\n",
            "Mck  Hnrrruuuuoh\n",
            " essuu sajywisteOkml Iohhes hbiewiouoaooueu\n",
            "!]h epeycehmllh<eehehy  ?ihh o\n",
            "eh rr-!ath[\n",
            ", Ksr eideeeuwuhht--iumh\n",
            "------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5rShVxgimcG",
        "outputId": "b18f794c-6d5c-498f-9a58-97f9231ef721"
      },
      "source": [
        "# this is a program used to calculate the similarity between the generated lyrics with the original ones\n",
        "\n",
        "lyrics = np.concatenate([generated, df['Lyric'].values]) # we need to put together the generated text and the original lyrics\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words=\"english\").fit_transform(lyrics) # vectorization process of the previous values\n",
        "\n",
        "pairwise_similarity = tfidf * tfidf.T # similarity matrix calculation \n",
        "\n",
        "pairwise_similarity = pairwise_similarity.toarray()[0] # converting it to an array\n",
        "    \n",
        "pairwise_similarity[0] = -1 # mask the diagonal element (the similarity to itself)\n",
        "   \n",
        "most_similar_idxs = pairwise_similarity.argsort()[-4:][::-1] # get the top 3 most similar lyrics to the generated lyrics\n",
        "most_similar_idxs =  most_similar_idxs[1:]\n",
        "\n",
        "output = [', '.join(df.iloc[most_similar_idxs - 1].SName),  # generate as output the title of the 3 most similar songs and their scores\n",
        "              *pairwise_similarity[most_similar_idxs], \n",
        "              most_similar_idxs - 1]\n",
        "\n",
        "print(\"similar to: {}\\n- scores: {}, {}, {}\".format(*output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "similar to: Teacher's Pet, Suzi (Wants Her All Day What?), Sunrise\n",
            "- scores: 0.0, 0.0, 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUnLin91rnoP",
        "outputId": "a0269e2e-56b0-4a6c-a797-d7f3958df5c6"
      },
      "source": [
        "# generation of the text with a title taken by an original song from the dataset\n",
        "\n",
        "generated = ''\n",
        "sentence = \"The Wait\"\n",
        "print('Seed:')\n",
        "print(sentence)\n",
        "print('------')\n",
        "\n",
        "for i in range(400):\n",
        "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(sentence):\n",
        "        x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "    preds = model.predict(x_pred, verbose=0)[0]\n",
        "    next_index = sample(preds, 1.0)\n",
        "    next_char = indices_char[next_index]\n",
        "\n",
        "    sentence = sentence[1:] + next_char\n",
        "    generated += next_char\n",
        "generated = generated.split('.')\n",
        "\n",
        "print('Generated text:')\n",
        "print('\\n'.join(generated))\n",
        "print('------')\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "The Wait\n",
            "------\n",
            "Generated text:\n",
            "dyihu]\n",
            "ohhIcothiBnhTstiuhthmhlmh<hr!htttol-tcooataaSNhhuhhuldiha\n",
            "icncl<bwbruS\n",
            " Sl!B\n",
            " feit Suhoo,thehotleBntouw-[uh\n",
            " uauihhhc?sculfdioirhmxh\n",
            "ea,eehehhBchmhS<ahi aeiBda\"houh-hhoaheshmehluthtuhew <DiecdaBn heiuwtomhavtlahhhuehu \n",
            "\n",
            "9oeTiocwToooihiolTouawkeh ho-CShi]FcScl o'o\n",
            "!waW\n",
            "m,]hh\n",
            "\n",
            "h\n",
            "auwhhiuot'waaaa ytonhlwa czth-tPwmhiuhul\n",
            "hwOatwwwhholo-lh hhkhtoaHw\n",
            "eShh\n",
            "ohcwuw<hihhWlhowaob-z\n",
            "ytui,lhhtmhhhl\n",
            "5srn)\n",
            "------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcoUuXEbrnaa",
        "outputId": "6823cf12-3945-416e-82a5-cec8d19466e7"
      },
      "source": [
        "# this is a program used to calculate the similarity between the generated lyrics with the original ones\n",
        "\n",
        "lyrics = np.concatenate([generated, df['Lyric'].values]) # we need to put together the generated text and the original lyrics\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words=\"english\").fit_transform(lyrics) # vectorization process of the previous values\n",
        "\n",
        "pairwise_similarity = tfidf * tfidf.T  # similarity matrix calculation \n",
        "\n",
        "pairwise_similarity = pairwise_similarity.toarray()[0] # converting it to an array\n",
        "    \n",
        "pairwise_similarity[0] = -1 # mask the diagonal element (the similarity to itself)\n",
        "    \n",
        "most_similar_idxs = pairwise_similarity.argsort()[-4:][::-1] # get the top 3 most similar lyrics to the generated lyrics\n",
        "most_similar_idxs =  most_similar_idxs[1:]\n",
        "\n",
        "output = [', '.join(df.iloc[most_similar_idxs - 1].SName), # generate as output the title of the 3 most similar songs and their scores\n",
        "              *pairwise_similarity[most_similar_idxs], \n",
        "              most_similar_idxs - 1]\n",
        "\n",
        "print(\"similar to: {}\\n- scores: {}, {}, {}\".format(*output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "similar to: Monica, Star, Song For Love\n",
            "- scores: 0.0, 0.0, 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-3hYR0QSbz7"
      },
      "source": [
        "## Generating text with different languages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sst5sXJijGM7"
      },
      "source": [
        "Here we will test our model with different languages input seeds, in particular by using Italian, Spanish and French"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69LflCBY78Nk",
        "outputId": "7334cabb-ce9c-4f1f-f402-0483c60eab5f"
      },
      "source": [
        "generated = ''\n",
        "sentence = \"Siamo fuori di testa, ma diversi da loro\"\n",
        "print('Seed:')\n",
        "print(sentence)\n",
        "print('------')\n",
        "\n",
        "for i in range(400):\n",
        "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(sentence):\n",
        "        x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "    preds = model.predict(x_pred, verbose=0)[0]\n",
        "    next_index = sample(preds, 1.0)\n",
        "    next_char = indices_char[next_index]\n",
        "\n",
        "    sentence = sentence[1:] + next_char\n",
        "    generated += next_char\n",
        "generated = generated.split('.')\n",
        "\n",
        "print('Generated text:')\n",
        "print('\\n'.join(generated))\n",
        "print('------')\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "Siamo fuori di testa, ma diversi da loro\n",
            "------\n",
            "Generated text:\n",
            "\n",
            " She llow I hall you natht in the way\n",
            " [Cow I'm a ready dirth beed ir tise\n",
            " Lot's rond We'll great fertevel on meerany\n",
            " For my homes\n",
            " for there amboting ready\n",
            " Bor my held os ferlot ald heave a but elack\n",
            " For my bad wigh a flaprid why\n",
            "\n",
            " Wo baidy oft of atw that tarn dan'\n",
            " I'm be tameem tel that you not\n",
            " Sur tam\n",
            " ald the poold reall for the plite\n",
            " Hor I wit a lood tomd, wat's 'Cause I't feel whe o\n",
            "------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMLMXy1chtrJ",
        "outputId": "55f762dc-bbd5-48db-f6b0-7e0c977d45a8"
      },
      "source": [
        "generated = ''\n",
        "sentence = \"Sí, sabes que ya llevo un rato mirándote\"\n",
        "print('Seed:')\n",
        "print(sentence)\n",
        "print('------')\n",
        "\n",
        "for i in range(400):\n",
        "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(sentence):\n",
        "        x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "    preds = model.predict(x_pred, verbose=0)[0]\n",
        "    next_index = sample(preds, 1.0)\n",
        "    next_char = indices_char[next_index]\n",
        "\n",
        "    sentence = sentence[1:] + next_char\n",
        "    generated += next_char\n",
        "generated = generated.split('.')\n",
        "\n",
        "print('Generated text:')\n",
        "print('\\n'.join(generated))\n",
        "print('------')\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "Sí, sabes que ya llevo un rato mirándote\n",
            "------\n",
            "Generated text:\n",
            "?\n",
            " A rock 't' rall\n",
            "\n",
            " Never might ic ut\n",
            " So down, dy my hey strow\n",
            " Anl oo cid to for off ay the gaig\n",
            " Coull me back in byoude\n",
            " Soven'm in the sky\n",
            " Blow Yeah you'll bee's rain my plare\n",
            " Ah yeahiye\n",
            " Shave ballshake, brain shake\n",
            " beais heall-me\n",
            " The e7win' bet ap¦stanmanfy starl\n",
            " I'm Shot bead whor you thing rock\n",
            " 'n' I'm gonta down on the plowr<EOT>\n",
            "\n",
            "\n",
            "<SOT>Hell ichere dee ssrock\n",
            " Reahe hone won't for\n",
            "------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhpJlW6XhtUV",
        "outputId": "a209bc1a-d899-464e-e464-666bb2abce13"
      },
      "source": [
        "generated = ''\n",
        "sentence = \"La vie c'est plus marrant\"\n",
        "print('Seed:')\n",
        "print(sentence)\n",
        "print('------')\n",
        "\n",
        "for i in range(400):\n",
        "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(sentence):\n",
        "        x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "    preds = model.predict(x_pred, verbose=0)[0]\n",
        "    next_index = sample(preds, 1.0)\n",
        "    next_char = indices_char[next_index]\n",
        "\n",
        "    sentence = sentence[1:] + next_char\n",
        "    generated += next_char\n",
        "generated = generated.split('.')\n",
        "\n",
        "print('Generated text:')\n",
        "print('\\n'.join(generated))\n",
        "print('------')\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "La vie c'est plus marrant\n",
            "------\n",
            "Generated text:\n",
            "hii)ciSteaSChoieiB\n",
            " \n",
            "hhlwAiciiomehheecrorniiwtwiethcoaRi)OOoh-hCaoa woaoioi\n",
            "iiihisihu'h<uh-aiwBigyeehhhhhstlheelbyyhluheltoycitimci<u oOcwoowhblhcoooaohetjni(nochninHichii\n",
            "ieilasuveii uuautaoirycOu[hehhh\n",
            "ih\n",
            "ahnpnuih\n",
            "ha<< hf2kNhchhs(iahee\n",
            "a>-\n",
            ")shr<gYilhhc°tiiiiehhseOsWhsieHhhaleliir\n",
            "rweic\n",
            "eah huooeu\n",
            "aarnoocrIEseeehciCDsoiooeewhhhmu\n",
            "fhfslnntnniriirahOm\n",
            "hsuhhhoOfzci\n",
            "hwtiiiior,e hhi(viwtntii\n",
            "9uhS\n",
            "hmdk\n",
            "------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}